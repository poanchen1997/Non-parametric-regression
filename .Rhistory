# import data
data <- read.table("fev.txt", header = T)
# check scatter plot
ggplot(data, aes(x = height, y = fev)) + geom_point()
# this script is used to compare the two type cross validation
library(ggplot2)
# import data
data <- read.table("fev.txt", header = T)
setwd("C:\Users\user\Downloads\GitHub Folder\Non-parametric-regression")
setwd("C:/Users/user/Downloads/GitHub Folder/Non-parametric-regression")
# import data
data <- read.table("fev.txt", header = T)
# check scatter plot
ggplot(data, aes(x = height, y = fev)) + geom_point()
max_h <- max(data$height) - min(data$height)
h_seq <- seq(0.5, max_h, 0.5)
mse_vector <- rep(0, length(h_seq))
for (i in 1:length(h_seq)){
h_using <- h_seq[i]
cv_mse <- rep(NA, length(data$height))
for (j in 1:length(data$height)){
y_val_predict <- ksmooth(data$height[-j], data$fev[-j], kernel = "box", bandwidth = h_using, x.points = data$height[j])
resid <- data$fev[j] - y_val_predict$y
cv_mse[j] <- resid^2
}
mse_vector[i] <- mean(cv_mse, na.rm = T)
}
mse_vector
plot(mse_vector)
h_seq[which.min(mse_vector)]
# band width 3 have the lowest mse
h_seq <- seq(0.5, max_h, 0.5)
mse_vector_k <- rep(0, length(h_seq))
K <- 5
for (i in 1:length(h_seq)){
h_using <- h_seq[i]
cv_mse <- rep(NA, K)
set.seed(111)
folds <- sample(rep(1:K, length = length(data$height)))
for (j in 1:K){
train <- folds != j
y_val_predict <- ksmooth(data$height[train], data$fev[train], kernel = "box", bandwidth = h_using, x.points = data$height[!train])
resid <- data$fev[!train][order(data$height[!train])] - y_val_predict$y
cv_mse[j] <- mean(resid^2)
}
mse_vector_k[i] <- mean(cv_mse, na.rm = T)
}
mse_vector_k
plot(mse_vector_k)
h_seq[which.min(mse_vector_k)]
model_loo <- ksmooth(data$height, data$fev, kernel = "box", bandwidth = 3)
resid_loo <- model_loo$y - data$fev[order(data$height)]
mean(resid_loo^2, na.rm = T)
model_kf <- ksmooth(data$height, data$fev, kernel = "box", bandwidth = 3)
resid_kf <- model_kf$y - data$fev[order(data$height)]
mean(resid_kf^2, na.rm = T)
plot(data$height, data$fev, pch = 20, xlab = "Height", ylab = "Fev")
lines(model_loo, col = 2, lwd = 3)
lines(model_kf, col = 4, lwd = 3)
legend(48, 5.5, legend=c("Loocv", "K-fold cv"),
col=c(2, 4), lty = 1, title = "Validation type")
plot(data$height, data$fev, pch = 20, xlab = "Height", ylab = "Fev")
lines(model_loo, col = 2, lwd = 3)
lines(model_kf, col = 4, lwd = 3)
data <- read.table("fev.txt", header = T)
# check scatter plot
ggplot(data, aes(x = height, y = fev)) + geom_point()
b <- 1.5 #bandwidth
kdeEstimateyX <- seq(min(x),max(x),.05)
ykernel <- NULL
for(xesti in kdeEstimateyX){
xx <-  xesti - x
K <-recKernel(xx,b)
Ksum <- sum(K)
weight <- K/Ksum
yk <- sum(weight*y)
xkyk <- c(xesti,yk)
ykernel <- rbind(ykernel,xkyk)
}
plot(x,y, pch = 20, xlab = "Height", ylab = "Fev")
lines(ykernel[,1],ykernel[,2], col = 2, lwd = 2)
x <- data$height
y <- data$fev
b <- 1.5 #bandwidth
kdeEstimateyX <- seq(min(x),max(x),.05)
ykernel <- NULL
for(xesti in kdeEstimateyX){
xx <-  xesti - x
K <-recKernel(xx,b)
Ksum <- sum(K)
weight <- K/Ksum
yk <- sum(weight*y)
xkyk <- c(xesti,yk)
ykernel <- rbind(ykernel,xkyk)
}
plot(x,y, pch = 20, xlab = "Height", ylab = "Fev")
lines(ykernel[,1],ykernel[,2], col = 2, lwd = 2)
recKernel <- function(x, b){
K <- ifelse(abs(x/b) <= 1, 1/2, 0)
return(K)
}
for(xesti in kdeEstimateyX){
xx <-  xesti - x
K <-recKernel(xx,b)
Ksum <- sum(K)
weight <- K/Ksum
yk <- sum(weight*y)
xkyk <- c(xesti,yk)
ykernel <- rbind(ykernel,xkyk)
}
plot(x,y, pch = 20, xlab = "Height", ylab = "Fev")
lines(ykernel[,1],ykernel[,2], col = 2, lwd = 2)
# Epanechnikov kernel
EKernel <- function(x, b){
K <- ifelse(abs(x/b) <= 1, (3/4)*(1-(x/b)^2), 0)
return(K)
}
kdeEstimateyX <- seq(min(x),max(x),.05)
ykernel <- NULL
for(xesti in kdeEstimateyX){
xx <-  xesti - x
K <-EKernel(xx,b)  # just change the function here
Ksum <- sum(K)
weight <- K/Ksum
yk <- sum(weight*y)
xkyk <- c(xesti,yk)
ykernel <- rbind(ykernel,xkyk)
}
lines(ykernel[,1],ykernel[,2], col = 2, lwd = 2)
boxKernel <- function(x, b){  # Using this kernel can have the same result with ksmooth
K <- ifelse(abs(x/b) <= .5, 1, 0)
return(K)
}
x <- data$height
y <- data$fev
b <- 1.5 #bandwidth
kdeEstimateyX <- seq(min(x),max(x),.05)
ykernel <- NULL
for(xesti in kdeEstimateyX){
xx <-  xesti - x
K <-boxKernel(xx,b)  # just change the function here
Ksum <- sum(K)
weight <- K/Ksum
yk <- sum(weight*y)
xkyk <- c(xesti,yk)
ykernel <- rbind(ykernel,xkyk)
}
plot(x,y, pch = 20, xlab = "Height", ylab = "Fev")
lines(ykernel[,1],ykernel[,2], col = 2, lwd = 2)
model_loo <- ksmooth(data$height, data$fev, kernel = "box", bandwidth = 3)
lines(model_loo, col = 2, lwd = 2)
boxKernel <- function(x, b){  # Using this kernel can have the same result with ksmooth
K <- ifelse(abs(x/b) <= .5, 1/2, 0)
return(K)
}
x <- data$height
y <- data$fev
b <- 1.5 #bandwidth
kdeEstimateyX <- seq(min(x),max(x),.05)
ykernel <- NULL
for(xesti in kdeEstimateyX){
xx <-  xesti - x
K <-boxKernel(xx,b)  # just change the function here
Ksum <- sum(K)
weight <- K/Ksum
yk <- sum(weight*y)
xkyk <- c(xesti,yk)
ykernel <- rbind(ykernel,xkyk)
}
plot(x,y, pch = 20, xlab = "Height", ylab = "Fev")
lines(ykernel[,1],ykernel[,2], col = 2, lwd = 2)
model_loo <- ksmooth(data$height, data$fev, kernel = "box", bandwidth = 3)
lines(model_loo, col = 2, lwd = 2)
boxKernel <- function(x, b){  # Using this kernel can have the same result with ksmooth
K <- ifelse(abs(x/b) <= .5, 1, 0)
return(K)
}
x <- data$height
y <- data$fev
b <- 1.5 #bandwidth
kdeEstimateyX <- seq(min(x),max(x),.05)
ykernel <- NULL
for(xesti in kdeEstimateyX){
xx <-  xesti - x
K <-boxKernel(xx,b)  # just change the function here
Ksum <- sum(K)
weight <- K/Ksum
yk <- sum(weight*y)
xkyk <- c(xesti,yk)
ykernel <- rbind(ykernel,xkyk)
}
plot(x,y, pch = 20, xlab = "Height", ylab = "Fev")
lines(ykernel[,1],ykernel[,2], col = 2, lwd = 2)
model_loo <- ksmooth(data$height, data$fev, kernel = "box", bandwidth = 1.5)
lines(model_loo, col = 2, lwd = 2)
e
e^1
exp()
pi
